{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUR Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the dMG configuration file with dHBV1.1p options:\n",
    "import sys\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "sys.path.append('../../dMG') # Add the root directory of dMG to the path\n",
    "from core.utils import initialize_config\n",
    "\n",
    "## Update the configuration file with PUR train/test options\n",
    "CONFIG_PATH = '../conf'\n",
    "CONFIG_NAME = 'dhbv_v1_1p_spatial_config'\n",
    "\n",
    "\n",
    "\n",
    "def load_config(config: str, config_name: str) -> DictConfig:\n",
    "    \"\"\" Initialize Hydra and parse model configuration yaml(s) into config dict. \"\"\"\n",
    "    with hydra.initialize(config_path=config, version_base='1.3'):\n",
    "        config = hydra.compose(config_name=config_name)\n",
    "   \n",
    "    config_dict = OmegaConf.to_container(config, resolve=True)\n",
    "\n",
    "    initialize_config(config_dict)\n",
    "    return config_dict\n",
    "\n",
    "config = load_config(CONFIG_PATH, CONFIG_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puN = 'PUR'\n",
    "# Divide CAMELS dataset into 7 continous PUR regions, as shown in Feng et al, 2021 GRL; 2022 HESSD\n",
    "# get the id list of each PUR region, save to list\n",
    "regionID = list()\n",
    "regionNum = list()\n",
    "# seven regions including different HUCs\n",
    "regionDivide = [ [1,2], [3,6], [4,5,7], [9,10], [8,11,12,13], [14,15,16,18], [17] ]\n",
    "for ii in range(len(regionDivide)):\n",
    "    tempcomb = regionDivide[ii]\n",
    "    tempregid = list()\n",
    "    for ih in tempcomb:\n",
    "        tempid = gageid[hucinfo==ih].tolist()\n",
    "        tempregid = tempregid + tempid\n",
    "    regionID.append(tempregid)\n",
    "    regionNum.append(len(tempregid))\n",
    "\n",
    "iexp = testfoldInd - 1  #index\n",
    "TestLS = regionID[iexp] # basin ID list for testing, hold out for training\n",
    "TestInd = [gageidLst.index(j) for j in TestLS]\n",
    "TrainLS = list(set(gageid.tolist()) - set(TestLS)) # basin ID for training\n",
    "TrainInd = [gageidLst.index(j) for j in TrainLS]\n",
    "gageDic = {'TrainID': TrainLS, 'TestID': TestLS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PUB Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "puN = 'PUB'\n",
    "# load the PUB basin groups\n",
    "# randomly divide CAMELS basins into 10 groups and this file contains the basin ID for each group\n",
    "# located in splitPath\n",
    "splitPath = 'PUBsplitLst.txt'\n",
    "with open(splitPath, 'r') as fp:\n",
    "    testIDLst=json.load(fp)\n",
    "# Generate training ID lists excluding the hold out fold\n",
    "TestLS = testIDLst[testfoldInd - 1]\n",
    "TestInd = [gageidLst.index(j) for j in TestLS]\n",
    "TrainLS = list(set(gageid.tolist()) - set(TestLS))\n",
    "TrainInd = [gageidLst.index(j) for j in TrainLS]\n",
    "gageDic = {'TrainID':TrainLS, 'TestID':TestLS}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrodl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
