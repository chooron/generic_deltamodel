{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MHPI hydroDL2.0 Tutorial: **dHBV1.1p**\n",
    "---\n",
    "\n",
    "This is a basic implementation of the generic differentiable modeling framework `dMG` using the HBV1.1p hydrology model\n",
    "plugin from the `hydroDL2.0` repository.\n",
    "\n",
    "\n",
    "\n",
    "Last Revision: 30 Oct. 2024\n",
    "\n",
    "Authors; Leo Lonzarich\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Basic Hands-off Deployment:\n",
    "\n",
    "In this first demonstration, we show how `dMG` using a HBV1.1p physics model backbone from `hydroDL2` can be operated\n",
    "in a  few steps. These are outlined as follows:\n",
    "\n",
    "0. First, ensure that you have the correct *env* configured. To avoid manually downloading required Python packages,\n",
    "create a `hydrodl` env using \n",
    "\n",
    "    `conda env create -f envs/hydrodl_env.yaml`.\n",
    "\n",
    "    Once activated, confirm PyTorch installed correctly with `torch.cuda.is_available()`. If this reports false, try\n",
    "    - `conda uninstall pytorch`\n",
    "    - `conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia`\n",
    "\n",
    "1. Set your desired model and experiment configuration settings within a *yaml* config file.\n",
    "    - For this tutorial, you can find this config located at `generic_diffModel/example/conf/dhbv_11p_config.yaml`. Note,\n",
    "    this yaml is configured to reproduce dHBV1.1p benchmarks for 531 CAMELS basins, trained and tested for 9 and 10 years,\n",
    "    respectively\n",
    "    - For normal use, however, see `generic_diffModel/conf/<your_config_here>`.\n",
    "2. Either run `python dMG/__main__.py` in your terminal, or (recommended) run the contents of `__main__.py` in the cells below.\n",
    "    - This will parse your config into a dictionary, load the HBV1.1p hydrology model, and begin training or testing.\n",
    "\n",
    "\n",
    "### 1.1 Create Configurations Dictionary\n",
    "\n",
    "The first cell below will convert the configurations yaml file into a key-indexed dictionary, with keys being the\n",
    "config settings. That is, if `mode: train` is set in `dhbv_11p_config.yaml`,the dictionary will yield `config['mode'] == 'train'`.\n",
    "Similarly, `training: start_time: 1999/10/01` is equivalent to `config['training']['start_time'] == '1999/10/01'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the dMG configuration file with dHBV1.1p options:\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "import hydra\n",
    "\n",
    "\n",
    "# Example configs stored in /example/conf\n",
    "CFG_PATH = '../conf'\n",
    "CFG_NAME = 'dhbv_11p_config'\n",
    "\n",
    "\n",
    "\n",
    "def load_config(relative_cfg_path: str, cfg_name: str) -> DictConfig:\n",
    "    \"\"\" Initialize Hydra and parse model configuration yaml(s) into config dict. \"\"\"\n",
    "    with hydra.initialize(config_path=relative_cfg_path, version_base='1.3'):\n",
    "        cfg = hydra.compose(config_name=cfg_name)\n",
    "   \n",
    "    cfg_dict = OmegaConf.to_container(cfg, resolve=True)\n",
    "    return cfg_dict\n",
    "\n",
    "config = load_config(CFG_PATH, CFG_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Run `__main__.py` with Configurations\n",
    "\n",
    "This code instantiates a model Trainer which will train or test a model per the user's specification in the config. Note\n",
    "that `__main__.py` is trimmed-down here to illustrate it's primary objective.\n",
    "Within the Trainer itself, \n",
    "- CAMELS data will be loaded and preprocessed,\n",
    "- A differenial model object with the HBV1.1p backbone will be created, and \n",
    "- An optimizer and loss function will be initialized.\n",
    "\n",
    "These and other details/structure of `dMG` will be illustrated in the second part of this tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../dMG') # Add the root directory of dMG to the path\n",
    "sys.path.append('../../example')\n",
    "\n",
    "import torch\n",
    "import logging\n",
    "from typing import Any, Dict\n",
    "from conf.config import ModeEnum\n",
    "from trainers import build_handler\n",
    "from core.utils import (create_output_dirs, randomseed_config, set_system_spec,\n",
    "                        show_args)\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def run_train_test(config_dict: Dict[str, Any]) -> None:\n",
    "    \"\"\"\n",
    "    Run training and testing as one experiment.\n",
    "    \"\"\"\n",
    "    # Training\n",
    "    config_dict['mode'] = ModeEnum.train\n",
    "    train_experiment_handler = build_handler(config_dict)\n",
    "    train_experiment_handler.run()\n",
    "\n",
    "    # Testing\n",
    "    config_dict['mode'] = ModeEnum.test\n",
    "    test_experiment_handler = build_handler(config_dict)            \n",
    "    test_experiment_handler.dplh_model_handler = train_experiment_handler.dplh_model_handler\n",
    "    test_experiment_handler.run()\n",
    "\n",
    "\n",
    "def run_experiment(config_dict: Dict[str, Any]) -> None:\n",
    "    \"\"\" Run an experiment based on the mode specified in the configuration. \"\"\"\n",
    "    experiment_handler = build_handler(config_dict)\n",
    "    experiment_handler.run()\n",
    "\n",
    "\n",
    "\n",
    "# Set device, dtype, output directories, and random seed.\n",
    "randomseed_config(config['random_seed'])\n",
    "\n",
    "config['device'], config['dtype'] = set_system_spec(config['gpu_id'])\n",
    "config = create_output_dirs(config)\n",
    "\n",
    "log.info(f\"RUNNING MODE: {config['mode']}\")\n",
    "show_args(config)\n",
    "\n",
    "# Run training and testing together, or one at a time.\n",
    "if config['mode'] == ModeEnum.train_test:\n",
    "    run_train_test(config)\n",
    "\n",
    "else:\n",
    "    run_experiment(config)\n",
    "\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Breakdown of Intermediate Steps\n",
    "\n",
    "\n",
    "### 2.1 Create Configurations Dictionary\n",
    "\n",
    "Once again, we begin by creating a configurations dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the dMG configuration file with dHBV1.1p options:\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "import hydra\n",
    "\n",
    "\n",
    "# Example configs stored in /example/conf\n",
    "CFG_PATH = '../conf'\n",
    "CFG_NAME = 'dhbv_11p_config'\n",
    "\n",
    "\n",
    "\n",
    "def load_config(relative_cfg_path: str, cfg_name: str) -> DictConfig:\n",
    "    \"\"\" Initialize Hydra and parse model configuration yaml(s) into config dict. \"\"\"\n",
    "    with hydra.initialize(config_path=relative_cfg_path, version_base='1.3'):\n",
    "        cfg = hydra.compose(config_name=cfg_name)\n",
    "   \n",
    "    cfg_dict = OmegaConf.to_container(cfg, resolve=True)\n",
    "    return cfg_dict\n",
    "\n",
    "config = load_config(CFG_PATH, CFG_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrodl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
